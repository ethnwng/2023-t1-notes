if $\mathbf{v}$ is an [[Eigenvector]] for $A$ with [[Eigenvalue]] $\lambda$. Then, $$A\vec{v}=\lambda\vec{v}$$
Consider the vector $\vec{u}=k\cdot\vec{v}$ for some scalar $k$ then, $$A\vec{u}=A(k\vec{v})=k\lambda\vec{v}=\lambda k \vec{v}=\lambda\vec{u}$$

Given two eigenvectors $\mathbf{v_{1},v_{2}}$ then is $A(\vec{v_{1}}+\vec{v_{2}})$ also an eigen vector
$$A(\vec{v_{1}}+\vec{v_{2}})=Av_{1}+Av_{1}=\lambda_{1}v_{1}+\lambda_{2}v_{2}$$The sum of two eigenvectors is not another eigenvector since the eigenvalues for both vectors are not always the same.

*if* $A$ has a non-trivial null space then $0$ is an eigenvalue for $A$. 
- Another way to test if some matrix is invertible is to find if $0$ is an eigenvalue for that matrix. 
- If it is the matrix is **not invertible**.


